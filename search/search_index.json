{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Engineer | Creature of the High Mountains | Himalayas Pacific Northwest Hi, I'm Aayush Uppal. Software Engineer, currently working for Facebook in Seattle and a University at Buffalo / NIT Hamirpur alumni. - Seattle, USA - Himachal Pradesh, India As a Software Engineer I am passionate about high performance distributed systems and building applications that provide critical machine learning enabled insight. Experienced Fullstack Engineer with core competency in Distributed Systems and Data Insight, Data Science Products. #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; } /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ I write occassionally | The Alpenglow Blog Current Endeavors Designing scalable distributed systems with a focus on analytics Linear Programming, Satisfiability Modulo Theories Building modern scalable web apps on the cloud with React/Python. Featured Kangra Valley Train in the Dhauladhars A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys The Dying Art of Disagreement More About Me I grew up in a picturesque town on the edge of Himalayas. Dharamshala Amongst other interests: Football , Blues Guitar , Hiking Pinned Trivia Nokia - NDTV App Idea Contest 2013, Amongst Top 20 nationwide finalists. Application for social good: Realtime blood donor locator Link to YouTube Video Last Updated: 2019-04-21","title":"Home"},{"location":"#home","text":"Engineer | Creature of the High Mountains | Himalayas Pacific Northwest Hi, I'm Aayush Uppal. Software Engineer, currently working for Facebook in Seattle and a University at Buffalo / NIT Hamirpur alumni. - Seattle, USA - Himachal Pradesh, India As a Software Engineer I am passionate about high performance distributed systems and building applications that provide critical machine learning enabled insight. Experienced Fullstack Engineer with core competency in Distributed Systems and Data Insight, Data Science Products. #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; } /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ I write occassionally | The Alpenglow Blog","title":"Home"},{"location":"#current-endeavors","text":"Designing scalable distributed systems with a focus on analytics Linear Programming, Satisfiability Modulo Theories Building modern scalable web apps on the cloud with React/Python.","title":"Current Endeavors"},{"location":"#featured","text":"Kangra Valley Train in the Dhauladhars A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys The Dying Art of Disagreement","title":"Featured"},{"location":"#more-about-me","text":"I grew up in a picturesque town on the edge of Himalayas. Dharamshala Amongst other interests: Football , Blues Guitar , Hiking Pinned","title":"More About Me"},{"location":"#trivia","text":"Nokia - NDTV App Idea Contest 2013, Amongst Top 20 nationwide finalists. Application for social good: Realtime blood donor locator Link to YouTube Video Last Updated: 2019-04-21","title":"Trivia"},{"location":"contact/","text":"Contact #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; } /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ I write occassionally | The Alpenglow Blog Email: LinkedIn - @uppalaayush GitHub - @aayushuppal Twitter - @aayushuppal Last Updated: 2020-04","title":"Contact"},{"location":"contact/#contact","text":"#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; } /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ I write occassionally | The Alpenglow Blog Email: LinkedIn - @uppalaayush GitHub - @aayushuppal Twitter - @aayushuppal Last Updated: 2020-04","title":"Contact"},{"location":"cv/","text":"Download Resume PDF here: \ud83d\udd17 pdf","title":"Cv"},{"location":"extras/","text":"Extras The Mountains A thread dedicated to sharing pictures, putting in words the appreciation for my backyard, the mighty Himalayas: The last frontier, the king of all mountains. Link Himalayas Mountains Himachal Pradesh Reading List Thus Spake Zarathustra - Friedrich Nietzsche : A book for None and All. Controversial and riveting, but the writing style takes some getting used to. A tremendously influential philosophical work of the 19 th century. Philosophy Morality Podcasts BBC - Thinking Allowed : New research on how society works. Sociology Matters of State : A podcast on International realtions and politics. International Relations Politics Last Updated: 2018-04-22","title":"Extras"},{"location":"extras/#extras","text":"","title":"Extras"},{"location":"extras/#the-mountains","text":"A thread dedicated to sharing pictures, putting in words the appreciation for my backyard, the mighty Himalayas: The last frontier, the king of all mountains. Link Himalayas Mountains Himachal Pradesh","title":"The Mountains"},{"location":"extras/#reading-list","text":"Thus Spake Zarathustra - Friedrich Nietzsche : A book for None and All. Controversial and riveting, but the writing style takes some getting used to. A tremendously influential philosophical work of the 19 th century. Philosophy Morality","title":"Reading List"},{"location":"extras/#podcasts","text":"BBC - Thinking Allowed : New research on how society works. Sociology Matters of State : A podcast on International realtions and politics. International Relations Politics Last Updated: 2018-04-22","title":"Podcasts"},{"location":"latest-work-au/","text":"What I am working on @ Bloomberg flowchart","title":"What I am working on"},{"location":"latest-work-au/#what-i-am-working-on","text":"","title":"What I am working on"},{"location":"latest-work-au/#bloomberg","text":"flowchart","title":"@ Bloomberg"},{"location":"lists/","text":"Lists The Mountain thread Kangra Valley Train Road Back Home Blog Posts Mantra - I The Dying Art of Disagreement Kangra Valley Train Representations This Developer Life Not All Shadows Calm of the Qualm Road Back Home Colors of Foliage Dev Posts Multi Processing with Queue - Python A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys Multi-Threading in Python Last Updated: 2019-04-14","title":"Lists"},{"location":"lists/#lists","text":"","title":"Lists"},{"location":"lists/#the-mountain-thread","text":"Kangra Valley Train Road Back Home","title":"The Mountain thread"},{"location":"lists/#blog-posts","text":"Mantra - I The Dying Art of Disagreement Kangra Valley Train Representations This Developer Life Not All Shadows Calm of the Qualm Road Back Home Colors of Foliage","title":"Blog Posts"},{"location":"lists/#dev-posts","text":"Multi Processing with Queue - Python A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys Multi-Threading in Python Last Updated: 2019-04-14","title":"Dev Posts"},{"location":"oss-cred/","text":"OSS Jinja Jinja is a fast, expressive, extensible templating engine. Special placeholders in the template allow writing code similar to Python syntax. Then the template is passed data to render the final document. Links pallets/jinja BHPQ A binary heap priority queue library for python Status Links pip package github Installation You can install bhpq from PyPI pip install bhpq bhpq is supported on Python 2.7 as well as Python 3.x SAPPGEN Simple App Generator for Python - Command line utility Status Links pip package github Installation You can install sappgen from PyPI pip install sappgen sappgen - Python 3.7 Last Updated: 2018-11-28","title":"OSS"},{"location":"oss-cred/#oss","text":"","title":"OSS"},{"location":"oss-cred/#jinja","text":"Jinja is a fast, expressive, extensible templating engine. Special placeholders in the template allow writing code similar to Python syntax. Then the template is passed data to render the final document.","title":" Jinja"},{"location":"oss-cred/#links","text":"pallets/jinja","title":"Links"},{"location":"oss-cred/#bhpq","text":"A binary heap priority queue library for python","title":" BHPQ"},{"location":"oss-cred/#status","text":"","title":"Status"},{"location":"oss-cred/#links_1","text":"pip package github","title":"Links"},{"location":"oss-cred/#installation","text":"You can install bhpq from PyPI pip install bhpq bhpq is supported on Python 2.7 as well as Python 3.x","title":"Installation"},{"location":"oss-cred/#sappgen","text":"Simple App Generator for Python - Command line utility","title":" SAPPGEN"},{"location":"oss-cred/#status_1","text":"","title":"Status"},{"location":"oss-cred/#links_2","text":"pip package github","title":"Links"},{"location":"oss-cred/#installation_1","text":"You can install sappgen from PyPI pip install sappgen sappgen - Python 3.7 Last Updated: 2018-11-28","title":"Installation"},{"location":"playlists/","text":"Playlists Music Alpenglow: https://sptfy.com/alpenglow Podcasts Pod Selects: https://lnns.co/DyamQjX6RHI","title":"Playlists"},{"location":"playlists/#playlists","text":"","title":"Playlists"},{"location":"playlists/#music","text":"Alpenglow: https://sptfy.com/alpenglow","title":"Music"},{"location":"playlists/#podcasts","text":"Pod Selects: https://lnns.co/DyamQjX6RHI","title":"Podcasts"},{"location":"profile/","text":"Profile Resume Work Bloomberg - Software Engineer New York, NY : May 2016 - Present Working as Software Engineer in Internal Systems and Web Applications group. Highlights Apache Spark based lifecycle analysis on a massive dataset. Communication Systems Distributed backend systems, core feature and infrastructure. Core communication systems infrastructure development for key aspects including modular state management overhaul, Enterprise System integration for more scale and load. Tools for continuous integration and development, a generic oozie based hadoop job manager. Key Backend Systems and Service Development. Spark Streaming Analysis for distributed logs. Pushing project ideas from the ground up to execution. Leading, Mentoring projects. Key Aspects: Design and Development, C++, Python, Distributed Systems, Data Science, Apache Spark Amazon - Software Development Engineer, Intern Seattle, WA : May 2015 - August 2015 Worked on designing a Pipeline based on TCP Anycast for experimental requests, reduced IP space consumption and performance analysis. Configured Anycast on a massive distributed network. Setup a pipeline to send requests via TCP Anycast to CDN cache servers. Collected RTT readings and setup Kinesis pipeline for processing. Wrote a Package for automated daily processing of day\u2019s RTT data and to generate comparative analysis reports between TCP Anycast and Latency Routing. Key aspects: Object oriented design, multi-threaded programming, Big Data, Cloud Computing. Skills: Linux shell scripting, Perl, Java, Python, Kinesis, Elastic Map Reduce, Hive SubBoard Inc | University at Buffalo - Student Assistantship, Web Developer Buffalo, NY : Oct 2014 - Dec 2015 Worked as Web Developer and Admin for SubBoard Web Portal. Key aspects: complete ownership - architecture, design, and maintainence of systems. Skills: MySQL, Server Administration, Amazon Web Services, Wordpress Compro Technologies - Software Engineer New Delhi, India : August 2013 - July 2014 MyITLab Sims project Cloud based HTML5 component development of MS Excel, MS PowerPoint features. Developed key components for web module including drawing pane, grid functionalities and graph components. This product is an industry leading training and assessment tool for professional and higher education segments. Key aspects: Agile development, testing, web services, object oriented analysis and design. Skills: Java, JavaScript, jQuery, SQL, HTML5, CSS National University of Singapore - Researcher, Intern Singapore : May 2012 - July 2012 Summer Intern at Solar Energy Research Institute of Singapore @ NUS, Singapore Worked on Raytracing of Solar Cells, to comeup with an effective implementation for simulating light trapping effeciency in solar cell models, involved mathematical, algorithm modeling Relied on C++ for extensibilty and better performance for the implementation Raytracing for Solar Cells Education State University of New York, University at Buffalo Buffalo, New York : August 2014 - February 2016 Masters in Computer Science GPA 3.86/4 Highlights Coursework focus: Distributed Systems, Artificial Intelligence and Machine Learning Projects Semantic Labeling of Images using SVM and Markov Blanket Android Group Messenger Classification Diabetes Level Prediction Mood based songs playlist using EEG Signals Neural Network for Classification of Handwritten Digits Dynamo style key value storage implementation Bayes Localization for Robot Motion Image Processing: Photometric Stereo Toolbox Implementation Disparity Depth estimation of Stereo view images using Dynamic Programming Boolean Query Search engine on news corpus AlumniConnect Distributed Hash Table News Search Engine, Story Representation and Analytics NIT Hamirpur Hamirpur, India : August 2009 - May 2013 Bachelors of Technology, Electronics and Communication Engineering GPA 7.5/10 Highlights Directorate of Technical Education Scholarship Holder Co-convener INS Controls Team leader, Electronics and Communication Engineering Executive Student Member, TIFAC Core Project Dam Warning System using GSM Performance Evaluation of WCDMA system Last Updated: 2018-05-07","title":"Profile"},{"location":"profile/#profile","text":"Resume","title":"Profile"},{"location":"profile/#work","text":"","title":"&gt; Work"},{"location":"profile/#bloomberg-software-engineer","text":"New York, NY : May 2016 - Present Working as Software Engineer in Internal Systems and Web Applications group. Highlights Apache Spark based lifecycle analysis on a massive dataset. Communication Systems Distributed backend systems, core feature and infrastructure. Core communication systems infrastructure development for key aspects including modular state management overhaul, Enterprise System integration for more scale and load. Tools for continuous integration and development, a generic oozie based hadoop job manager. Key Backend Systems and Service Development. Spark Streaming Analysis for distributed logs. Pushing project ideas from the ground up to execution. Leading, Mentoring projects. Key Aspects: Design and Development, C++, Python, Distributed Systems, Data Science, Apache Spark","title":"Bloomberg - Software Engineer"},{"location":"profile/#amazon-software-development-engineer-intern","text":"Seattle, WA : May 2015 - August 2015 Worked on designing a Pipeline based on TCP Anycast for experimental requests, reduced IP space consumption and performance analysis. Configured Anycast on a massive distributed network. Setup a pipeline to send requests via TCP Anycast to CDN cache servers. Collected RTT readings and setup Kinesis pipeline for processing. Wrote a Package for automated daily processing of day\u2019s RTT data and to generate comparative analysis reports between TCP Anycast and Latency Routing. Key aspects: Object oriented design, multi-threaded programming, Big Data, Cloud Computing. Skills: Linux shell scripting, Perl, Java, Python, Kinesis, Elastic Map Reduce, Hive","title":"Amazon - Software Development Engineer, Intern"},{"location":"profile/#subboard-inc-university-at-buffalo-student-assistantship-web-developer","text":"Buffalo, NY : Oct 2014 - Dec 2015 Worked as Web Developer and Admin for SubBoard Web Portal. Key aspects: complete ownership - architecture, design, and maintainence of systems. Skills: MySQL, Server Administration, Amazon Web Services, Wordpress","title":"SubBoard Inc | University at Buffalo - Student Assistantship, Web Developer"},{"location":"profile/#compro-technologies-software-engineer","text":"New Delhi, India : August 2013 - July 2014 MyITLab Sims project Cloud based HTML5 component development of MS Excel, MS PowerPoint features. Developed key components for web module including drawing pane, grid functionalities and graph components. This product is an industry leading training and assessment tool for professional and higher education segments. Key aspects: Agile development, testing, web services, object oriented analysis and design. Skills: Java, JavaScript, jQuery, SQL, HTML5, CSS","title":"Compro Technologies - Software Engineer"},{"location":"profile/#national-university-of-singapore-researcher-intern","text":"Singapore : May 2012 - July 2012 Summer Intern at Solar Energy Research Institute of Singapore @ NUS, Singapore Worked on Raytracing of Solar Cells, to comeup with an effective implementation for simulating light trapping effeciency in solar cell models, involved mathematical, algorithm modeling Relied on C++ for extensibilty and better performance for the implementation Raytracing for Solar Cells","title":"National University of Singapore - Researcher, Intern"},{"location":"profile/#education","text":"","title":"&gt; Education"},{"location":"profile/#state-university-of-new-york-university-at-buffalo","text":"Buffalo, New York : August 2014 - February 2016 Masters in Computer Science GPA 3.86/4 Highlights Coursework focus: Distributed Systems, Artificial Intelligence and Machine Learning Projects Semantic Labeling of Images using SVM and Markov Blanket Android Group Messenger Classification Diabetes Level Prediction Mood based songs playlist using EEG Signals Neural Network for Classification of Handwritten Digits Dynamo style key value storage implementation Bayes Localization for Robot Motion Image Processing: Photometric Stereo Toolbox Implementation Disparity Depth estimation of Stereo view images using Dynamic Programming Boolean Query Search engine on news corpus AlumniConnect Distributed Hash Table News Search Engine, Story Representation and Analytics","title":"State University of New York, University at Buffalo"},{"location":"profile/#nit-hamirpur","text":"Hamirpur, India : August 2009 - May 2013 Bachelors of Technology, Electronics and Communication Engineering GPA 7.5/10 Highlights Directorate of Technical Education Scholarship Holder Co-convener INS Controls Team leader, Electronics and Communication Engineering Executive Student Member, TIFAC Core Project Dam Warning System using GSM Performance Evaluation of WCDMA system Last Updated: 2018-05-07","title":"NIT Hamirpur"},{"location":"blog/art_disagreement/","text":"The Dying Art of Disagreement Links New York Times - Article: https://www.nytimes.com/2017/09/24/opinion/dying-art-of-disagreement.html Lowy Institute - Bret Stephens lecture: https://youtu.be/7ZQq-QA8118?t=15m43s What Stands Out To disagree well you must first understand well You have to read deeply, listen carefully and watch closely. Empathy and Respect for Adversary You need to grant your adversary moral respect and intellectual benefit of doubt. Sympathy for their motives and participate empathically with the line of reasoning. Allow for the possibility of persusasion. On masking opinions from challenge I recognise as this therefore I think can be a dangerous precedent. On the purpose of opinion The purpose of opinion isn\u2019t to depart from facts but to use them as a bridge to a larger idea called truth .","title":"The Dying Art of Disagreement"},{"location":"blog/art_disagreement/#the-dying-art-of-disagreement","text":"Links New York Times - Article: https://www.nytimes.com/2017/09/24/opinion/dying-art-of-disagreement.html Lowy Institute - Bret Stephens lecture: https://youtu.be/7ZQq-QA8118?t=15m43s What Stands Out To disagree well you must first understand well You have to read deeply, listen carefully and watch closely. Empathy and Respect for Adversary You need to grant your adversary moral respect and intellectual benefit of doubt. Sympathy for their motives and participate empathically with the line of reasoning. Allow for the possibility of persusasion. On masking opinions from challenge I recognise as this therefore I think can be a dangerous precedent. On the purpose of opinion The purpose of opinion isn\u2019t to depart from facts but to use them as a bridge to a larger idea called truth .","title":"The Dying Art of Disagreement"},{"location":"blog/calm_qualm/","text":"Calm of the Qualm Aayush Uppal | 2016 \u201c To comprehend is not a concern to be, cause justification ain\u2019t the order of the disorder.\u201d The tree that stands in a storm, A wind that strikes your face. Every leaf that is stripped of it and in the fall of a branch. There lies a resistance to every single blow and a disorder for the wanted. It\u2019s time when sense has a jurisdiction that gets felt. The wrath seems to be a nagging pain, and when urgency overrides every reason and culminates in a qualm. There lies a particular rosiness to this disorder, the sense of disengaging and the idea of destruction. The peace of mind and the calm of the qualm is a rather violent expression to peace. It\u2019s when mind feels numb and the single streak of the faintest expression multiplies, segregates and defragments. The still in this storm is a rockier one, a steadier one, the one that apparently resides and hides in our pangs. The feeling of being a part of an expression that we visibly connect to elevates our emotions and the being to be rid of these pangs gets stronger in the storm. A release that finally escapes in the mid of it gives a weird numbness. An intoxication of a tranquil trance, a sense of control and of all the things in hand. Apprehensions seem to die and a pandemonium arises. Things that may have felt so cynical but for the moment the moment beholds ceases and overrides a worldly sense. Palpable it gets all through even to the slightest to the smallest of fragments of conscience. This expressionism that defies mind soothes within and spreads a calm. \"These ideas seem quasi but the storm ain\u2019t, A flaw seems to be the logic but the expression ain\u2019t.\" thoughts , restless mind","title":"Calm of the Qualm"},{"location":"blog/calm_qualm/#calm-of-the-qualm","text":"Aayush Uppal | 2016","title":"Calm of the Qualm"},{"location":"blog/colors_of_foliage/","text":"Colors Of Foliage Aayush Uppal | 2014 Colors of Foliage abstract , thoughts , nature , foliage , seasons","title":"Colors of Foliage"},{"location":"blog/colors_of_foliage/#colors-of-foliage","text":"Aayush Uppal | 2014 Colors of Foliage abstract , thoughts , nature , foliage , seasons","title":"Colors Of Foliage"},{"location":"blog/kangra-valley-train/","text":"The Kangra Valley Train Aayush Uppal | 2018-04-22 If you think of it, a picture is a 3D space representation. It spans across time with the idea it captures across the literal distance it maps on to the canvas and well nothing brings this idea to more prominence than this picture above. But that isn't the only reason I find this so captivating. Those mountains right in the backdrop are something I am fond of, the nooks and crevices etched on that landscape are more familiar to me than the lines on the back of my hand. The line thins for a picture like this for someone like me, is it the picture I am looking at or the memory that plays back. If I close my eyes It almost plays back as a motion poster through the dense greens from the far edge on a clear evening after the rain. himachal pradesh , himalayas , train , nostalgia , mountains Photo Credits: Premola Ghose, Ram Rahman. Link to Book","title":"Kangra Valley Train"},{"location":"blog/kangra-valley-train/#the-kangra-valley-train","text":"Aayush Uppal | 2018-04-22 If you think of it, a picture is a 3D space representation. It spans across time with the idea it captures across the literal distance it maps on to the canvas and well nothing brings this idea to more prominence than this picture above. But that isn't the only reason I find this so captivating. Those mountains right in the backdrop are something I am fond of, the nooks and crevices etched on that landscape are more familiar to me than the lines on the back of my hand. The line thins for a picture like this for someone like me, is it the picture I am looking at or the memory that plays back. If I close my eyes It almost plays back as a motion poster through the dense greens from the far edge on a clear evening after the rain. himachal pradesh , himalayas , train , nostalgia , mountains Photo Credits: Premola Ghose, Ram Rahman. Link to Book","title":"The Kangra Valley Train"},{"location":"blog/mantra-i/","text":"Mantra - I Aayush Uppal | 2018-07-22 Stimulus Cognition Reaction","title":"Mantra - I"},{"location":"blog/mantra-i/#mantra-i","text":"Aayush Uppal | 2018-07-22 Stimulus Cognition Reaction","title":"Mantra - I"},{"location":"blog/not_all_shadows/","text":"Not All Shadows Aayush Uppal | 2017 Not all shadows hide something, Some shadows reveal the overlooked. abstract , art , mafalda silva , quote , shadow , thoughts Photo Credits: Mafalda Silva","title":"Not All Shadows"},{"location":"blog/not_all_shadows/#not-all-shadows","text":"Aayush Uppal | 2017 Not all shadows hide something, Some shadows reveal the overlooked. abstract , art , mafalda silva , quote , shadow , thoughts Photo Credits: Mafalda Silva","title":"Not All Shadows"},{"location":"blog/representations/","text":"Representations Aayush Uppal | 2017 Representations do not replace relaities, rather they just convey how meanings were created. abstract , design , minimal , thoughts","title":"Representations"},{"location":"blog/representations/#representations","text":"Aayush Uppal | 2017 Representations do not replace relaities, rather they just convey how meanings were created. abstract , design , minimal , thoughts","title":"Representations"},{"location":"blog/road_back_home/","text":"The Road Back Home Prologue Aayush Uppal | 2015 The Road Back Home | Prologue Dharamshala , Nostalgia , Prologue , The road back home , mountains","title":"Road Back Home"},{"location":"blog/road_back_home/#the-road-back-home","text":"","title":"The Road Back Home"},{"location":"blog/road_back_home/#prologue","text":"Aayush Uppal | 2015 The Road Back Home | Prologue Dharamshala , Nostalgia , Prologue , The road back home , mountains","title":"Prologue"},{"location":"blog/this_dev_life/","text":"This Developer Life Aayush Uppal | 2017 this developer life _ code , design , dev , developer , life , minimal , poster , wallpaper","title":"This Developer Life"},{"location":"blog/this_dev_life/#this-developer-life","text":"Aayush Uppal | 2017 this developer life _ code , design , dev , developer , life , minimal , poster , wallpaper","title":"This Developer Life"},{"location":"devposts/chronological-file-org/","text":"Chronologically organise files - Python utility April 2020 Code snippet #!/usr/bin/env python3.7 ============================== Chronological File Organizer ============================== aayushuppal.github.io April 2020 from datetime import datetime from pathlib import Path import shutil IN_DIR = Path ( /path/to/to-do-org-dir ) OUT_DIR = Path ( /path/to/chrono-org-dir ) def dtm_to_out_file_path ( dtm : datetime , filename : str ): y = dtm . year m = dtm . month p = OUT_DIR / f {y:04} / f {m:02} p . mkdir ( parents = True , exist_ok = True ) return p / filename if __name__ == __main__ : in_dir = IN_DIR out_dir = OUT_DIR assert in_dir . exists () == True for p in in_dir . rglob ( * ): file_name = p . name file_mod_dtm = datetime . fromtimestamp ( p . stat () . st_mtime ) file_in_path = p file_out_path = dtm_to_out_file_path ( file_mod_dtm , file_name ) if file_out_path . exists (): print ( f duplicate exists - cannot move {file_name} from {file_in_path} to {file_out_path} ) else : shutil . move ( file_in_path , file_out_path )","title":"Chronological file organizer"},{"location":"devposts/chronological-file-org/#chronologically-organise-files-python-utility","text":"April 2020 Code snippet #!/usr/bin/env python3.7 ============================== Chronological File Organizer ============================== aayushuppal.github.io April 2020 from datetime import datetime from pathlib import Path import shutil IN_DIR = Path ( /path/to/to-do-org-dir ) OUT_DIR = Path ( /path/to/chrono-org-dir ) def dtm_to_out_file_path ( dtm : datetime , filename : str ): y = dtm . year m = dtm . month p = OUT_DIR / f {y:04} / f {m:02} p . mkdir ( parents = True , exist_ok = True ) return p / filename if __name__ == __main__ : in_dir = IN_DIR out_dir = OUT_DIR assert in_dir . exists () == True for p in in_dir . rglob ( * ): file_name = p . name file_mod_dtm = datetime . fromtimestamp ( p . stat () . st_mtime ) file_in_path = p file_out_path = dtm_to_out_file_path ( file_mod_dtm , file_name ) if file_out_path . exists (): print ( f duplicate exists - cannot move {file_name} from {file_in_path} to {file_out_path} ) else : shutil . move ( file_in_path , file_out_path )","title":"Chronologically organise files - Python utility"},{"location":"devposts/devposts1/","text":"Dev Posts Building with React NextJS March 2018 //TODO The wild west of email threads February 2018 //TODO Streaming analytics on logs 2017 distributed systems logging Apache Spark Spark Streaming I had been wanting to experiment with the spark streaming framework for a while now, ever since I first got my hands on with the spark framework itself to work on a lifecycle analysis application that processed over a TB of data and generated meaningful clustered outputs. Spark Streaming for the uninitiated is a powerful platform that enables realtime analysis. The Problem at hand: I am sure many developers in this day and age have at some point or the other run into a situation losing context ever so often while debugging an error or an anomalous behaviour trying to keep track of one identifier for incoming request mapped to second and that mapped to the third just to see where in all the event went through and processed in its lifecycle. It particularly becomes even harder when your system is event driven and maintains state for decision making. So here's what I decided to do. Build a spark streaming application that reads logs from multiple services in realtime from a message queue. Process it in memory up until the corresponding event/request context expires. Aggregate all required information for that particular event into a user defined structured data type. Define trigger conditions for alerts and dumps of error/warn and pass the object containing all the logically mapped info for the program/developer to analyse. Last Updated: 2018-04-22","title":"DP/Pg/I"},{"location":"devposts/devposts1/#dev-posts","text":"","title":"Dev Posts"},{"location":"devposts/devposts1/#building-with-react-nextjs","text":"March 2018 //TODO","title":"Building with React &amp; NextJS"},{"location":"devposts/devposts1/#the-wild-west-of-email-threads","text":"February 2018 //TODO","title":"The wild west of email threads"},{"location":"devposts/devposts1/#streaming-analytics-on-logs","text":"2017 distributed systems logging Apache Spark Spark Streaming I had been wanting to experiment with the spark streaming framework for a while now, ever since I first got my hands on with the spark framework itself to work on a lifecycle analysis application that processed over a TB of data and generated meaningful clustered outputs. Spark Streaming for the uninitiated is a powerful platform that enables realtime analysis. The Problem at hand: I am sure many developers in this day and age have at some point or the other run into a situation losing context ever so often while debugging an error or an anomalous behaviour trying to keep track of one identifier for incoming request mapped to second and that mapped to the third just to see where in all the event went through and processed in its lifecycle. It particularly becomes even harder when your system is event driven and maintains state for decision making. So here's what I decided to do. Build a spark streaming application that reads logs from multiple services in realtime from a message queue. Process it in memory up until the corresponding event/request context expires. Aggregate all required information for that particular event into a user defined structured data type. Define trigger conditions for alerts and dumps of error/warn and pass the object containing all the logically mapped info for the program/developer to analyse. Last Updated: 2018-04-22","title":"Streaming analytics on logs"},{"location":"devposts/multi_processing_queue/","text":"Queue and Multi Processing Pool - Python May 2019 Interfacing multiprocessing queue to delegate tasks to multiprocessing pool in python Code snippet #!/usr/bin/env python3.7 from multiprocessing import Pool , Queue from os import getpid from time import sleep from queue import Empty from random import randint QUEUE_TIMEOUT = 5 # seconds proc_queue = Queue () def worker_fn ( queue : Queue ): print ( f {getpid()} working ) try : while True : item = queue . get ( block = True , timeout = QUEUE_TIMEOUT ) sleep ( randint ( 1 , 4 )) print ( f {getpid()} got {item} ) except Empty : print ( f {getpid()} stopping ) proc_pool = Pool ( processes = 4 , initializer = worker_fn , initargs = ( proc_queue ,)) for i in range ( 10 ): payload = { id : i } proc_queue . put ( payload ) proc_pool . close () proc_pool . join () Using multiprocessing pool with async worker function and callback Code snippet #!/usr/bin/env python3.7 from os import getpid import multiprocessing from time import sleep def worker_fn ( payload ): sleep ( 1 ) print ( f {getpid()} processing {payload} ) return f {getpid()}-{payload[ id ]} def callback_fn ( val ): print ( f callback {val} ) if __name__ == __main__ : proc_pool = multiprocessing . Pool ( 4 ) for i in range ( 0 , 10 ): payload = { id : i } proc_pool . apply_async ( worker_fn , args = ( payload ,), callback = callback_fn ) proc_pool . close () proc_pool . join ()","title":"Multi Processing with Queue"},{"location":"devposts/multi_processing_queue/#queue-and-multi-processing-pool-python","text":"May 2019 Interfacing multiprocessing queue to delegate tasks to multiprocessing pool in python Code snippet #!/usr/bin/env python3.7 from multiprocessing import Pool , Queue from os import getpid from time import sleep from queue import Empty from random import randint QUEUE_TIMEOUT = 5 # seconds proc_queue = Queue () def worker_fn ( queue : Queue ): print ( f {getpid()} working ) try : while True : item = queue . get ( block = True , timeout = QUEUE_TIMEOUT ) sleep ( randint ( 1 , 4 )) print ( f {getpid()} got {item} ) except Empty : print ( f {getpid()} stopping ) proc_pool = Pool ( processes = 4 , initializer = worker_fn , initargs = ( proc_queue ,)) for i in range ( 10 ): payload = { id : i } proc_queue . put ( payload ) proc_pool . close () proc_pool . join () Using multiprocessing pool with async worker function and callback Code snippet #!/usr/bin/env python3.7 from os import getpid import multiprocessing from time import sleep def worker_fn ( payload ): sleep ( 1 ) print ( f {getpid()} processing {payload} ) return f {getpid()}-{payload[ id ]} def callback_fn ( val ): print ( f callback {val} ) if __name__ == __main__ : proc_pool = multiprocessing . Pool ( 4 ) for i in range ( 0 , 10 ): payload = { id : i } proc_pool . apply_async ( worker_fn , args = ( payload ,), callback = callback_fn ) proc_pool . close () proc_pool . join ()","title":"Queue and Multi Processing Pool - Python"},{"location":"devposts/multi_threading_python/","text":"Multi-Threading in Python May 2018 A reference implementation of multi threading network requests for better perfromance with python3. TODO : Parallelize GET requests to fetch data over the network. Creating a Thread Worker class that extends Thread and has a task_queue Set an action_type to reuse the worker for different type of actions that the worker queue can be reused for. from threading import Thread from util.data_util import getData class ThreadWorker(Thread): def __init__(self, queue): Thread.__init__(self) self.task_queue = queue def run(self): while True: action_type, args = self.task_queue.get() if action_type == getData : getData(args=args) self.task_queue.task_done() Writing the Data Util for GET requests to fetch data Using **kwargs for generic named param args as a dict. Using an output container to return content. import urllib.request from urllib.error import HTTPError def getData(**kwargs): args = kwargs[ args ] try: content = urllib.request.urlopen(args[ get_url ]).read() except HTTPError: content = None args[ output ][ content ] = content Creating and starting a multi threaded task queue from queue import Queue task_queue = Queue() for i in range(CPU_COUNT): worker = ThreadWorker(task_queue) worker.daemon = True worker.start() Putting tasks in task queue output1 = {} task_queue.put(( getData ,{ get_url : http://google.com , output : output1})) output2 = {} task_queue.put(( getData ,{ get_url : http://example.com , output : output2})) Waiting for tasks to finish task_queue.join() Output getData for= http://example.com takes time=0.04711198806762695s getData for= http://example.com takes time=0.04711198806762695s getData for= http://example.com takes time=0.04514908790588379s getData for= http://google.com takes time=0.1752634048461914s getData for= http://google.com takes time=0.17326903343200684s getData for= http://google.com takes time=0.1590442657470703s main takes time=0.2101454734802246s serial exec time would be time=0.6469497680664062s Source code: PyUtils/MultiThread","title":"Multi Threading Python"},{"location":"devposts/multi_threading_python/#multi-threading-in-python","text":"May 2018 A reference implementation of multi threading network requests for better perfromance with python3. TODO : Parallelize GET requests to fetch data over the network. Creating a Thread Worker class that extends Thread and has a task_queue Set an action_type to reuse the worker for different type of actions that the worker queue can be reused for. from threading import Thread from util.data_util import getData class ThreadWorker(Thread): def __init__(self, queue): Thread.__init__(self) self.task_queue = queue def run(self): while True: action_type, args = self.task_queue.get() if action_type == getData : getData(args=args) self.task_queue.task_done() Writing the Data Util for GET requests to fetch data Using **kwargs for generic named param args as a dict. Using an output container to return content. import urllib.request from urllib.error import HTTPError def getData(**kwargs): args = kwargs[ args ] try: content = urllib.request.urlopen(args[ get_url ]).read() except HTTPError: content = None args[ output ][ content ] = content Creating and starting a multi threaded task queue from queue import Queue task_queue = Queue() for i in range(CPU_COUNT): worker = ThreadWorker(task_queue) worker.daemon = True worker.start() Putting tasks in task queue output1 = {} task_queue.put(( getData ,{ get_url : http://google.com , output : output1})) output2 = {} task_queue.put(( getData ,{ get_url : http://example.com , output : output2})) Waiting for tasks to finish task_queue.join() Output getData for= http://example.com takes time=0.04711198806762695s getData for= http://example.com takes time=0.04711198806762695s getData for= http://example.com takes time=0.04514908790588379s getData for= http://google.com takes time=0.1752634048461914s getData for= http://google.com takes time=0.17326903343200684s getData for= http://google.com takes time=0.1590442657470703s main takes time=0.2101454734802246s serial exec time would be time=0.6469497680664062s Source code: PyUtils/MultiThread","title":"Multi-Threading in Python"},{"location":"devposts/multiple_git/","text":"Set up multiple git user accounts on your machine per repository Nov 2018 Multiple SSH Keys for different github accounts generate and add ssh keys for both users user1 and user2 user1 ssh-keygen -t rsa -b 4096 -C user1@email.com /home/user/.ssh/id_user1 user2 ssh-keygen -t rsa -b 4096 -C user2@email.com /home/user/.ssh/id_user2 sshconfig ~/.ssh/config # default account identity - set to user1 Host github.com HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user1 Host github.com-user1 HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user2 Host github.com-user2 HostName github.com User git IdentityFile /home/user/.ssh/id_user2 reset all global git settings git config --global user.useConfigOnly true git config --global --unset-all user.name git config --global --unset-all user.email set the repo clone a repo set repo level .git/.gitconfig, eg: git config user.name user1 git config user.email user1l@email.com to explicitly use a user specific setting update the remote to git clone git@github.com-user1:user1/repo.git Last Updated: 2018-11-02","title":"Multiple Git Accounts"},{"location":"devposts/multiple_git/#set-up-multiple-git-user-accounts-on-your-machine-per-repository","text":"Nov 2018 Multiple SSH Keys for different github accounts","title":"Set up multiple git user accounts on your machine per repository"},{"location":"devposts/multiple_git/#generate-and-add-ssh-keys-for-both-users-user1-and-user2","text":"user1 ssh-keygen -t rsa -b 4096 -C user1@email.com /home/user/.ssh/id_user1 user2 ssh-keygen -t rsa -b 4096 -C user2@email.com /home/user/.ssh/id_user2","title":"generate and add ssh keys for both users user1 and user2"},{"location":"devposts/multiple_git/#sshconfig-sshconfig","text":"# default account identity - set to user1 Host github.com HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user1 Host github.com-user1 HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user2 Host github.com-user2 HostName github.com User git IdentityFile /home/user/.ssh/id_user2","title":"sshconfig ~/.ssh/config"},{"location":"devposts/multiple_git/#reset-all-global-git-settings","text":"git config --global user.useConfigOnly true git config --global --unset-all user.name git config --global --unset-all user.email","title":"reset all global git settings"},{"location":"devposts/multiple_git/#set-the-repo","text":"clone a repo set repo level .git/.gitconfig, eg: git config user.name user1 git config user.email user1l@email.com to explicitly use a user specific setting update the remote to git clone git@github.com-user1:user1/repo.git Last Updated: 2018-11-02","title":"set the repo"},{"location":"devposts/root-rom-samsung/","text":"Root and Custom ROM Samsung Android Phone Nov 2018 After recently having bricked my realtively new One Plus 5 phone on a recent motorbiking trip (albeit biking on the highest motorable road in the world), I decided to overhaul my 2014 Samsung Galaxy Grand 2. Here is a summary of my experience overhauling it to get it to work rather smoothly. Flash TWRP recovery using Odin TWRP 3.0.0 Recovery Samsung Win Drivers Odin 3.07 Install Cyanogenmod ROM+ Boot in TWRP recovery Cyanogenmod 13 Patch 1 Patch 2 Bare minimum GApps, ARM-6.0-pico Install Cyanogenmod ROM + Patches + GApps Root the phone Boot into TWRP recovery SuperSU flashable Install SuperSU Rerference Links https://forum.xda-developers.com/galaxy-grand-2/orig-development/rom-cyanogenmod-13-galaxy-grand-2-t3485393 https://www.cyanogenmods.org/forums/topic/galaxy-grand-2-cm13-cyanogenmod-13-marshmallow-rom-sm-g7102/","title":"Root & Custom Rom Android"},{"location":"devposts/root-rom-samsung/#root-and-custom-rom-samsung-android-phone","text":"Nov 2018 After recently having bricked my realtively new One Plus 5 phone on a recent motorbiking trip (albeit biking on the highest motorable road in the world), I decided to overhaul my 2014 Samsung Galaxy Grand 2. Here is a summary of my experience overhauling it to get it to work rather smoothly.","title":"Root and Custom ROM Samsung Android Phone"},{"location":"devposts/root-rom-samsung/#flash-twrp-recovery-using-odin","text":"TWRP 3.0.0 Recovery Samsung Win Drivers Odin 3.07","title":"Flash TWRP recovery using Odin"},{"location":"devposts/root-rom-samsung/#install-cyanogenmod-rom","text":"Boot in TWRP recovery Cyanogenmod 13 Patch 1 Patch 2 Bare minimum GApps, ARM-6.0-pico Install Cyanogenmod ROM + Patches + GApps","title":"Install Cyanogenmod ROM+"},{"location":"devposts/root-rom-samsung/#root-the-phone","text":"Boot into TWRP recovery SuperSU flashable Install SuperSU","title":"Root the phone"},{"location":"devposts/root-rom-samsung/#rerference-links","text":"https://forum.xda-developers.com/galaxy-grand-2/orig-development/rom-cyanogenmod-13-galaxy-grand-2-t3485393 https://www.cyanogenmods.org/forums/topic/galaxy-grand-2-cm13-cyanogenmod-13-marshmallow-rom-sm-g7102/","title":"Rerference Links"},{"location":"devposts/sde-journaling-guide/","text":"A Software Engineer's Guide to Journaling Apr 2019 A Software Engineer's Guide to Journaling To impart value you need to make sense and to make sense you need to be able to see how an idea evolves, thus Journaling.Personally having experimented with various tools and strategies that go along with each one of them I was finally able to settle upon the following as a well defined structured approach with a timeline for each step.","title":"SDE Guide to Journaling"},{"location":"devposts/sde-journaling-guide/#a-software-engineers-guide-to-journaling","text":"Apr 2019","title":"A Software Engineer's Guide to Journaling"},{"location":"drafts/ordinary-emotion/","text":"Ordinary Emotion Aayush Uppal | 2018-04-23 But what is ordinary may never last, yet more often than not it does. Often chasing the grandest of ideas I don't know what it is. So at this point I am not quite sure if there is an ordinary emotion anymore. But what I do know is my perspective has evolved and I feel like I am going to hold dear to the moment.","title":"Ordinary Emotion"},{"location":"drafts/ordinary-emotion/#ordinary-emotion","text":"Aayush Uppal | 2018-04-23 But what is ordinary may never last, yet more often than not it does. Often chasing the grandest of ideas I don't know what it is. So at this point I am not quite sure if there is an ordinary emotion anymore. But what I do know is my perspective has evolved and I feel like I am going to hold dear to the moment.","title":"Ordinary Emotion"}]}