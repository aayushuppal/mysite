{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 Engineer | Creature of the High Mountains | Himalayas NYC Hi, I'm Aayush Uppal. Software Engineer - Lead Developer, currently working for Bloomberg in New York City and a University at Buffalo / NIT Hamirpur alumni. - New York, USA - Himachal Pradesh, India As a Software Engineer I am passionate about high performance distributed systems and building applications that provide critical machine learning enabled insight. Experienced Fullstack Engineer with core competency in Distributed Systems and Data Insight Products. Profile Resume Open Source Cred Medium: @aayushuppal Current Endeavors \u00b6 Recurrent Neural Networks for Time Series Analysis and Prediction Linear Programming, Satisfiability Modulo Theories Building modern scalable web apps on the cloud with React/Python. Machine learning, data science. Data Science for Good Featured \u00b6 Multi Processing with Queue - Python A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys Mantra - I Multi-Threading in Python The Dying Art of Disagreement Kangra Valley Train in the stunning backdrop of Dhauladhars More About Me \u00b6 I grew up in a picturesque town on the edge of Himalayas. Dharamshala Check out my thread dedicated to the amazing place. Link Amongst other key interests: Football , Blues Guitar Pinned Trivia \u00b6 Nokia - NDTV App Idea Contest 2013, Amongst Top 20 nationwide finalists. Application for social good: Realtime blood donor locator Link to YouTube Video Last Updated: 2019-04-21 \u21a9","title":"Home"},{"location":"#home","text":"Engineer | Creature of the High Mountains | Himalayas NYC Hi, I'm Aayush Uppal. Software Engineer - Lead Developer, currently working for Bloomberg in New York City and a University at Buffalo / NIT Hamirpur alumni. - New York, USA - Himachal Pradesh, India As a Software Engineer I am passionate about high performance distributed systems and building applications that provide critical machine learning enabled insight. Experienced Fullstack Engineer with core competency in Distributed Systems and Data Insight Products. Profile Resume Open Source Cred Medium: @aayushuppal","title":"Home"},{"location":"#current-endeavors","text":"Recurrent Neural Networks for Time Series Analysis and Prediction Linear Programming, Satisfiability Modulo Theories Building modern scalable web apps on the cloud with React/Python. Machine learning, data science. Data Science for Good","title":"Current Endeavors"},{"location":"#featured","text":"Multi Processing with Queue - Python A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys Mantra - I Multi-Threading in Python The Dying Art of Disagreement Kangra Valley Train in the stunning backdrop of Dhauladhars","title":"Featured"},{"location":"#more-about-me","text":"I grew up in a picturesque town on the edge of Himalayas. Dharamshala Check out my thread dedicated to the amazing place. Link Amongst other key interests: Football , Blues Guitar Pinned","title":"More About Me"},{"location":"#trivia","text":"Nokia - NDTV App Idea Contest 2013, Amongst Top 20 nationwide finalists. Application for social good: Realtime blood donor locator Link to YouTube Video Last Updated: 2019-04-21 \u21a9","title":"Trivia"},{"location":"contact/","text":"Contact \u00b6 Get in touch or drop a message to collaborate \u00b6 Request Failed! Try Again. Message Email address Submit Thank you for reaching out. Processing Request... You can also find me at: @LinkedIn @GitHub @BitBucket @Twitter Email: aayuppal@gmail.com function validateForm() { var emailField = $(\"#emailInputField\")[0].value.trim() var isEmailValid = emailField.match(/^([\\w.%+-]+)@([\\w-]+\\.)+([\\w]{2,})$/i) var msgField = $(\"#msgInputField\")[0].value.trim() var isMsgValid = msgField.length >= 2 if (isEmailValid == null || !isMsgValid) { document.getElementById(\"submitButton\").disabled=true return false } document.getElementById(\"submitButton\").disabled=false return true } function submitEmail() { isValidForm = validateForm() if (!isValidForm) { return } var emailField = document.getElementById(\"emailInputField\").value.trim() var msgField = $(\"#msgInputField\")[0].value.trim() var url = \"https://rp-dbasvc-v2.herokuapp.com/add-gen-msg\" document.getElementById(\"Contact_Form\").style.display = \"none\" document.getElementById(\"Contact_Failed\").style.display = \"none\" document.getElementById(\"Contact_Successful\").style.display = \"none\" document.getElementById(\"Contact_processing\").style.display = \"block\" fetch(url, { method: \"POST\", headers: { \"Accept\": \"application/json\", \"Content-Type\": \"application/json\" }, body: JSON.stringify({ email: emailField, message: msgField, referral: \"aayushuppal.github.io\" }) }) .then(handleResponse) .then(handleSuccess) .catch(handleErrors) } function handleResponse(response) { if (!response.ok) { throw Error(response.statusText) } return response } function handleSuccess(response) { document.getElementById(\"Contact_Failed\").style.display = \"none\" document.getElementById(\"Contact_processing\").style.display = \"none\" document.getElementById(\"Contact_Form\").style.display = \"none\" document.getElementById(\"Contact_Successful\").style.display = \"block\" } function handleErrors(error) { document.getElementById(\"Contact_Successful\").style.display = \"none\" document.getElementById(\"Contact_processing\").style.display = \"none\" document.getElementById(\"Contact_Failed\").style.display = \"block\" document.getElementById(\"Contact_Form\").style.display = \"block\" } Last Updated: 2018-11-18 \u21a9","title":"Contact"},{"location":"contact/#contact","text":"","title":"Contact"},{"location":"contact/#get-in-touch-or-drop-a-message-to-collaborate","text":"","title":"Get in touch or drop a message to collaborate"},{"location":"cv/","text":"Download Resume PDF here: \ud83d\udd17 pdf","title":"Cv"},{"location":"extras/","text":"Extras \u00b6 The Mountains \u00b6 A thread dedicated to sharing pictures, putting in words the appreciation for my backyard, the mighty Himalayas: The last frontier, the king of all mountains. Link Himalayas Mountains Himachal Pradesh Reading List \u00b6 Thus Spake Zarathustra - Friedrich Nietzsche : A book for None and All. Controversial and riveting, but the writing style takes some getting used to. A tremendously influential philosophical work of the 19 th century. Philosophy Morality Podcasts \u00b6 BBC - Thinking Allowed : New research on how society works. Sociology Matters of State : A podcast on International realtions and politics. International Relations Politics Last Updated: 2018-04-22 \u21a9","title":"Extras"},{"location":"extras/#extras","text":"","title":"Extras"},{"location":"extras/#the-mountains","text":"A thread dedicated to sharing pictures, putting in words the appreciation for my backyard, the mighty Himalayas: The last frontier, the king of all mountains. Link Himalayas Mountains Himachal Pradesh","title":"The Mountains"},{"location":"extras/#reading-list","text":"Thus Spake Zarathustra - Friedrich Nietzsche : A book for None and All. Controversial and riveting, but the writing style takes some getting used to. A tremendously influential philosophical work of the 19 th century. Philosophy Morality","title":"Reading List"},{"location":"extras/#podcasts","text":"BBC - Thinking Allowed : New research on how society works. Sociology Matters of State : A podcast on International realtions and politics. International Relations Politics Last Updated: 2018-04-22 \u21a9","title":"Podcasts"},{"location":"lists/","text":"Lists \u00b6 The Mountain thread \u00b6 Kangra Valley Train Road Back Home Blog Posts \u00b6 Mantra - I The Dying Art of Disagreement Kangra Valley Train Representations This Developer Life Not All Shadows Calm of the Qualm Road Back Home Colors of Foliage Dev Posts \u00b6 Multi Processing with Queue - Python A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys Multi-Threading in Python Last Updated: 2019-04-14 \u21a9","title":"Lists"},{"location":"lists/#lists","text":"","title":"Lists"},{"location":"lists/#the-mountain-thread","text":"Kangra Valley Train Road Back Home","title":"The Mountain thread"},{"location":"lists/#blog-posts","text":"Mantra - I The Dying Art of Disagreement Kangra Valley Train Representations This Developer Life Not All Shadows Calm of the Qualm Road Back Home Colors of Foliage","title":"Blog Posts"},{"location":"lists/#dev-posts","text":"Multi Processing with Queue - Python A Software Engineer's Guide to Journaling Multiple Git Accounts - SSH Keys Multi-Threading in Python Last Updated: 2019-04-14 \u21a9","title":"Dev Posts"},{"location":"oss-cred/","text":"Open Source Cred \u00b6 BHPQ \u00b6 A binary heap priority queue library for python Status \u00b6 Links \u00b6 pip package github Installation \u00b6 You can install bhpq from PyPI pip install bhpq bhpq is supported on Python 2.7 as well as Python 3.x SAPPGEN \u00b6 Simple App Generator for Python - Command line utility Status \u00b6 Links \u00b6 pip package github Installation \u00b6 You can install sappgen from PyPI pip install sappgen sappgen - Python 3.7 Last Updated: 2018-11-28 \u21a9","title":"Open Source"},{"location":"oss-cred/#open-source-cred","text":"","title":"Open Source Cred"},{"location":"oss-cred/#bhpq","text":"A binary heap priority queue library for python","title":" BHPQ"},{"location":"oss-cred/#status","text":"","title":"Status"},{"location":"oss-cred/#links","text":"pip package github","title":"Links"},{"location":"oss-cred/#installation","text":"You can install bhpq from PyPI pip install bhpq bhpq is supported on Python 2.7 as well as Python 3.x","title":"Installation"},{"location":"oss-cred/#sappgen","text":"Simple App Generator for Python - Command line utility","title":" SAPPGEN"},{"location":"oss-cred/#status_1","text":"","title":"Status"},{"location":"oss-cred/#links_1","text":"pip package github","title":"Links"},{"location":"oss-cred/#installation_1","text":"You can install sappgen from PyPI pip install sappgen sappgen - Python 3.7 Last Updated: 2018-11-28 \u21a9","title":"Installation"},{"location":"playlists/","text":"Playlists \u00b6 Podcasts \u00b6 Pod Selects: https://lnns.co/DyamQjX6RHI Music \u00b6 Blues & Selects: https://sptfy.com/8U6J","title":"Playlists"},{"location":"playlists/#playlists","text":"","title":"Playlists"},{"location":"playlists/#podcasts","text":"Pod Selects: https://lnns.co/DyamQjX6RHI","title":"Podcasts"},{"location":"playlists/#music","text":"Blues & Selects: https://sptfy.com/8U6J","title":"Music"},{"location":"profile/","text":"Profile \u00b6 Resume > Work \u00b6 Bloomberg - Software Engineer \u00b6 New York, NY : May 2016 - Present Working as Software Engineer in Internal Systems and Web Applications group. Highlights Apache Spark based lifecycle analysis on a massive dataset. Communication Systems Distributed backend systems, core feature and infrastructure. Core communication systems infrastructure development for key aspects including modular state management overhaul, Enterprise System integration for more scale and load. Tools for continuous integration and development, a generic oozie based hadoop job manager. Key Backend Systems and Service Development. Spark Streaming Analysis for distributed logs. Pushing product ideas from the ground up to execution. Taking complete ownership for continuous development. Mentoring projects. Key Aspects: Design and Development, C++, Python, Distributed Systems, Data Science, Apache Spark Amazon - Software Development Engineer, Intern \u00b6 Seattle, WA : May 2015 - August 2015 Worked on designing a Pipeline based on TCP Anycast for experimental requests, reduced IP space consumption and performance analysis. Configured Anycast on a massive distributed network. Setup a pipeline to send requests via TCP Anycast to CDN cache servers. Collected RTT readings and setup Kinesis pipeline for processing. Wrote a Package for automated daily processing of day\u2019s RTT data and to generate comparative analysis reports between TCP Anycast and Latency Routing. Key aspects: Object oriented design, multi-threaded programming, Big Data, Cloud Computing. Skills: Linux shell scripting, Perl, Java, Python, Kinesis, Elastic Map Reduce, Hive SubBoard Inc | University at Buffalo - Student Assistantship, Web Developer \u00b6 Buffalo, NY : Oct 2014 - Dec 2015 Worked as Web Developer and Admin for SubBoard Web Portal. Key aspects: complete ownership - architecture, design, and maintainence of systems. Skills: MySQL, Server Administration, Amazon Web Services, Wordpress Compro Technologies - Software Engineer \u00b6 New Delhi, India : August 2013 - July 2014 MyITLab Sims project Cloud based HTML5 component development of MS Excel, MS PowerPoint features. Developed key components for web module including drawing pane, grid functionalities and graph components. This product is an industry leading training and assessment tool for professional and higher education segments. Key aspects: Agile development, testing, web services, object oriented analysis and design. Skills: Java, JavaScript, jQuery, SQL, HTML5, CSS National University of Singapore - Researcher, Intern \u00b6 Singapore : May 2012 - July 2012 Summer Intern at Solar Energy Research Institute of Singapore @ NUS, Singapore Worked on Raytracing of Solar Cells, to comeup with an effective implementation for simulating light trapping effeciency in solar cell models, involved mathematical, algorithm modeling Relied on C++ for extensibilty and better performance for the implementation Raytracing for Solar Cells > Education \u00b6 State University of New York, University at Buffalo \u00b6 Buffalo, New York : August 2014 - February 2016 Masters in Computer Science GPA 3.86/4 Highlights Coursework focus: Distributed Systems, Artificial Intelligence and Machine Learning Projects Semantic Labeling of Images using SVM and Markov Blanket Android Group Messenger Classification & Diabetes Level Prediction Mood based songs playlist using EEG Signals Neural Network for Classification of Handwritten Digits Dynamo style key value storage implementation Bayes Localization for Robot Motion Image Processing: Photometric Stereo Toolbox Implementation Disparity & Depth estimation of Stereo view images using Dynamic Programming Boolean Query Search engine on news corpus AlumniConnect Distributed Hash Table News Search Engine, Story Representation and Analytics NIT Hamirpur \u00b6 Hamirpur, India : August 2009 - May 2013 Bachelors of Technology, Electronics and Communication Engineering GPA 7.5/10 Highlights Directorate of Technical Education Scholarship Holder Co-convener INS & Controls Team leader, Electronics and Communication Engineering Executive Student Member, TIFAC Core Project Dam Warning System using GSM Performance Evaluation of WCDMA system Last Updated: 2018-05-07 \u21a9","title":"Profile"},{"location":"profile/#profile","text":"Resume","title":"Profile"},{"location":"profile/#work","text":"","title":"&gt; Work"},{"location":"profile/#bloomberg-software-engineer","text":"New York, NY : May 2016 - Present Working as Software Engineer in Internal Systems and Web Applications group. Highlights Apache Spark based lifecycle analysis on a massive dataset. Communication Systems Distributed backend systems, core feature and infrastructure. Core communication systems infrastructure development for key aspects including modular state management overhaul, Enterprise System integration for more scale and load. Tools for continuous integration and development, a generic oozie based hadoop job manager. Key Backend Systems and Service Development. Spark Streaming Analysis for distributed logs. Pushing product ideas from the ground up to execution. Taking complete ownership for continuous development. Mentoring projects. Key Aspects: Design and Development, C++, Python, Distributed Systems, Data Science, Apache Spark","title":"Bloomberg - Software Engineer"},{"location":"profile/#amazon-software-development-engineer-intern","text":"Seattle, WA : May 2015 - August 2015 Worked on designing a Pipeline based on TCP Anycast for experimental requests, reduced IP space consumption and performance analysis. Configured Anycast on a massive distributed network. Setup a pipeline to send requests via TCP Anycast to CDN cache servers. Collected RTT readings and setup Kinesis pipeline for processing. Wrote a Package for automated daily processing of day\u2019s RTT data and to generate comparative analysis reports between TCP Anycast and Latency Routing. Key aspects: Object oriented design, multi-threaded programming, Big Data, Cloud Computing. Skills: Linux shell scripting, Perl, Java, Python, Kinesis, Elastic Map Reduce, Hive","title":"Amazon - Software Development Engineer, Intern"},{"location":"profile/#subboard-inc-university-at-buffalo-student-assistantship-web-developer","text":"Buffalo, NY : Oct 2014 - Dec 2015 Worked as Web Developer and Admin for SubBoard Web Portal. Key aspects: complete ownership - architecture, design, and maintainence of systems. Skills: MySQL, Server Administration, Amazon Web Services, Wordpress","title":"SubBoard Inc | University at Buffalo - Student Assistantship, Web Developer"},{"location":"profile/#compro-technologies-software-engineer","text":"New Delhi, India : August 2013 - July 2014 MyITLab Sims project Cloud based HTML5 component development of MS Excel, MS PowerPoint features. Developed key components for web module including drawing pane, grid functionalities and graph components. This product is an industry leading training and assessment tool for professional and higher education segments. Key aspects: Agile development, testing, web services, object oriented analysis and design. Skills: Java, JavaScript, jQuery, SQL, HTML5, CSS","title":"Compro Technologies - Software Engineer"},{"location":"profile/#national-university-of-singapore-researcher-intern","text":"Singapore : May 2012 - July 2012 Summer Intern at Solar Energy Research Institute of Singapore @ NUS, Singapore Worked on Raytracing of Solar Cells, to comeup with an effective implementation for simulating light trapping effeciency in solar cell models, involved mathematical, algorithm modeling Relied on C++ for extensibilty and better performance for the implementation Raytracing for Solar Cells","title":"National University of Singapore - Researcher, Intern"},{"location":"profile/#education","text":"","title":"&gt; Education"},{"location":"profile/#state-university-of-new-york-university-at-buffalo","text":"Buffalo, New York : August 2014 - February 2016 Masters in Computer Science GPA 3.86/4 Highlights Coursework focus: Distributed Systems, Artificial Intelligence and Machine Learning Projects Semantic Labeling of Images using SVM and Markov Blanket Android Group Messenger Classification & Diabetes Level Prediction Mood based songs playlist using EEG Signals Neural Network for Classification of Handwritten Digits Dynamo style key value storage implementation Bayes Localization for Robot Motion Image Processing: Photometric Stereo Toolbox Implementation Disparity & Depth estimation of Stereo view images using Dynamic Programming Boolean Query Search engine on news corpus AlumniConnect Distributed Hash Table News Search Engine, Story Representation and Analytics","title":"State University of New York, University at Buffalo"},{"location":"profile/#nit-hamirpur","text":"Hamirpur, India : August 2009 - May 2013 Bachelors of Technology, Electronics and Communication Engineering GPA 7.5/10 Highlights Directorate of Technical Education Scholarship Holder Co-convener INS & Controls Team leader, Electronics and Communication Engineering Executive Student Member, TIFAC Core Project Dam Warning System using GSM Performance Evaluation of WCDMA system Last Updated: 2018-05-07 \u21a9","title":"NIT Hamirpur"},{"location":"blog/art_disagreement/","text":"The Dying Art of Disagreement \u00b6 Links New York Times - Article: https://www.nytimes.com/2017/09/24/opinion/dying-art-of-disagreement.html Lowy Institute - Bret Stephens lecture: https://youtu.be/7ZQq-QA8118?t=15m43s What Stands Out To disagree well you must first understand well You have to read deeply, listen carefully and watch closely. Empathy and Respect for Adversary You need to grant your adversary moral respect and intellectual benefit of doubt. Sympathy for their motives and participate empathically with the line of reasoning. Allow for the possibility of persusasion. On masking opinions from challenge I recognise as this therefore I think can be a dangerous precedent. On the purpose of opinion The purpose of opinion isn\u2019t to depart from facts but to use them as a bridge to a larger idea called truth .","title":"The Dying Art of Disagreement"},{"location":"blog/art_disagreement/#the-dying-art-of-disagreement","text":"Links New York Times - Article: https://www.nytimes.com/2017/09/24/opinion/dying-art-of-disagreement.html Lowy Institute - Bret Stephens lecture: https://youtu.be/7ZQq-QA8118?t=15m43s What Stands Out To disagree well you must first understand well You have to read deeply, listen carefully and watch closely. Empathy and Respect for Adversary You need to grant your adversary moral respect and intellectual benefit of doubt. Sympathy for their motives and participate empathically with the line of reasoning. Allow for the possibility of persusasion. On masking opinions from challenge I recognise as this therefore I think can be a dangerous precedent. On the purpose of opinion The purpose of opinion isn\u2019t to depart from facts but to use them as a bridge to a larger idea called truth .","title":"The Dying Art of Disagreement"},{"location":"blog/calm_qualm/","text":"Calm of the Qualm \u00b6 Aayush Uppal | 2016 \u201c To comprehend is not a concern to be, cause justification ain\u2019t the order of the disorder.\u201d The tree that stands in a storm, A wind that strikes your face. Every leaf that is stripped of it and in the fall of a branch. There lies a resistance to every single blow and a disorder for the wanted. It\u2019s time when sense has a jurisdiction that gets felt. The wrath seems to be a nagging pain, and when urgency overrides every reason and culminates in a qualm. There lies a particular rosiness to this disorder, the sense of disengaging and the idea of destruction. The peace of mind and the calm of the qualm is a rather violent expression to peace. It\u2019s when mind feels numb and the single streak of the faintest expression multiplies, segregates and defragments. The still in this storm is a rockier one, a steadier one, the one that apparently resides and hides in our pangs. The feeling of being a part of an expression that we visibly connect to elevates our emotions and the being to be rid of these pangs gets stronger in the storm. A release that finally escapes in the mid of it gives a weird numbness. An intoxication of a tranquil trance, a sense of control and of all the things in hand. Apprehensions seem to die and a pandemonium arises. Things that may have felt so cynical but for the moment the moment beholds ceases and overrides a worldly sense. Palpable it gets all through even to the slightest to the smallest of fragments of conscience. This expressionism that defies mind soothes within and spreads a calm. \"These ideas seem quasi but the storm ain\u2019t, A flaw seems to be the logic but the expression ain\u2019t.\" thoughts , restless mind \u21a9","title":"Calm of the Qualm"},{"location":"blog/calm_qualm/#calm-of-the-qualm","text":"Aayush Uppal | 2016","title":"Calm of the Qualm"},{"location":"blog/colors_of_foliage/","text":"Colors Of Foliage \u00b6 Aayush Uppal | 2014 Colors of Foliage abstract , thoughts , nature , foliage , seasons \u21a9","title":"Colors of Foliage"},{"location":"blog/colors_of_foliage/#colors-of-foliage","text":"Aayush Uppal | 2014 Colors of Foliage abstract , thoughts , nature , foliage , seasons \u21a9","title":"Colors Of Foliage"},{"location":"blog/kangra-valley-train/","text":"The Kangra Valley Train \u00b6 Aayush Uppal | 2018-04-22 If you think of it, a picture is a 3D space representation. It spans across time with the idea it captures across the literal distance it maps on to the canvas and well nothing brings this idea to more prominence than this picture above. But that isn't the only reason I find this so captivating. Those mountains right in the backdrop are something I am fond of, the nooks and crevices etched on that landscape are more familiar to me than the lines on the back of my hand. The line thins for a picture like this for someone like me, is it the picture I am looking at or the memory that plays back. If I close my eyes It almost plays back as a motion poster through the dense greens from the far edge on a clear evening after the rain. himachal pradesh , himalayas , train , nostalgia , mountains \u21a9 Photo Credits: Premola Ghose, Ram Rahman. Link to Book \u21a9","title":"Kangra Valley Train"},{"location":"blog/kangra-valley-train/#the-kangra-valley-train","text":"Aayush Uppal | 2018-04-22 If you think of it, a picture is a 3D space representation. It spans across time with the idea it captures across the literal distance it maps on to the canvas and well nothing brings this idea to more prominence than this picture above. But that isn't the only reason I find this so captivating. Those mountains right in the backdrop are something I am fond of, the nooks and crevices etched on that landscape are more familiar to me than the lines on the back of my hand. The line thins for a picture like this for someone like me, is it the picture I am looking at or the memory that plays back. If I close my eyes It almost plays back as a motion poster through the dense greens from the far edge on a clear evening after the rain. himachal pradesh , himalayas , train , nostalgia , mountains \u21a9 Photo Credits: Premola Ghose, Ram Rahman. Link to Book \u21a9","title":"The Kangra Valley Train"},{"location":"blog/mantra-i/","text":"Mantra - I \u00b6 Aayush Uppal | 2018-07-22 Stimulus > Cognition > Reaction","title":"Mantra - I"},{"location":"blog/mantra-i/#mantra-i","text":"Aayush Uppal | 2018-07-22 Stimulus > Cognition > Reaction","title":"Mantra - I"},{"location":"blog/not_all_shadows/","text":"Not All Shadows \u00b6 Aayush Uppal | 2017 Not all shadows hide something, Some shadows reveal the overlooked. abstract , art , mafalda silva , quote , shadow , thoughts \u21a9 Photo Credits: Mafalda Silva \u21a9","title":"Not All Shadows"},{"location":"blog/not_all_shadows/#not-all-shadows","text":"Aayush Uppal | 2017 Not all shadows hide something, Some shadows reveal the overlooked. abstract , art , mafalda silva , quote , shadow , thoughts \u21a9 Photo Credits: Mafalda Silva \u21a9","title":"Not All Shadows"},{"location":"blog/representations/","text":"Representations \u00b6 Aayush Uppal | 2017 Representations do not replace relaities, rather they just convey how meanings were created. abstract , design , minimal , thoughts \u21a9","title":"Representations"},{"location":"blog/representations/#representations","text":"Aayush Uppal | 2017 Representations do not replace relaities, rather they just convey how meanings were created. abstract , design , minimal , thoughts \u21a9","title":"Representations"},{"location":"blog/road_back_home/","text":"The Road Back Home \u00b6 Prologue \u00b6 Aayush Uppal | 2015 The Road Back Home | Prologue Dharamshala , Nostalgia , Prologue , The road back home , mountains \u21a9","title":"Road Back Home"},{"location":"blog/road_back_home/#the-road-back-home","text":"","title":"The Road Back Home"},{"location":"blog/road_back_home/#prologue","text":"Aayush Uppal | 2015 The Road Back Home | Prologue Dharamshala , Nostalgia , Prologue , The road back home , mountains \u21a9","title":"Prologue"},{"location":"blog/this_dev_life/","text":"This Developer Life \u00b6 Aayush Uppal | 2017 this developer life _ code , design , dev , developer , life , minimal , poster , wallpaper \u21a9","title":"This Developer Life"},{"location":"blog/this_dev_life/#this-developer-life","text":"Aayush Uppal | 2017 this developer life _ code , design , dev , developer , life , minimal , poster , wallpaper \u21a9","title":"This Developer Life"},{"location":"devposts/devposts1/","text":"Dev Posts \u00b6 Building with React & NextJS \u00b6 March 2018 //TODO The wild west of email threads \u00b6 February 2018 //TODO Streaming analytics on logs \u00b6 2017 distributed systems logging Apache Spark Spark Streaming I had been wanting to experiment with the spark streaming framework for a while now, ever since I first got my hands on with the spark framework itself to work on a lifecycle analysis application that processed over a TB of data and generated meaningful clustered outputs. Spark Streaming for the uninitiated is a powerful platform that enables realtime analysis. The Problem at hand: I am sure many developers in this day and age have at some point or the other run into a situation losing context ever so often while debugging an error or an anomalous behaviour trying to keep track of one identifier for incoming request mapped to second and that mapped to the third just to see where in all the event went through and processed in its lifecycle. It particularly becomes even harder when your system is event driven and maintains state for decision making. So here's what I decided to do. Build a spark streaming application that reads logs from multiple services in realtime from a message queue. Process it in memory up until the corresponding event/request context expires. Aggregate all required information for that particular event into a user defined structured data type. Define trigger conditions for alerts and dumps of error/warn and pass the object containing all the logically mapped info for the program/developer to analyse. Last Updated: 2018-04-22 \u21a9","title":"DP/Pg/I"},{"location":"devposts/devposts1/#dev-posts","text":"","title":"Dev Posts"},{"location":"devposts/devposts1/#building-with-react-nextjs","text":"March 2018 //TODO","title":"Building with React &amp; NextJS"},{"location":"devposts/devposts1/#the-wild-west-of-email-threads","text":"February 2018 //TODO","title":"The wild west of email threads"},{"location":"devposts/devposts1/#streaming-analytics-on-logs","text":"2017 distributed systems logging Apache Spark Spark Streaming I had been wanting to experiment with the spark streaming framework for a while now, ever since I first got my hands on with the spark framework itself to work on a lifecycle analysis application that processed over a TB of data and generated meaningful clustered outputs. Spark Streaming for the uninitiated is a powerful platform that enables realtime analysis. The Problem at hand: I am sure many developers in this day and age have at some point or the other run into a situation losing context ever so often while debugging an error or an anomalous behaviour trying to keep track of one identifier for incoming request mapped to second and that mapped to the third just to see where in all the event went through and processed in its lifecycle. It particularly becomes even harder when your system is event driven and maintains state for decision making. So here's what I decided to do. Build a spark streaming application that reads logs from multiple services in realtime from a message queue. Process it in memory up until the corresponding event/request context expires. Aggregate all required information for that particular event into a user defined structured data type. Define trigger conditions for alerts and dumps of error/warn and pass the object containing all the logically mapped info for the program/developer to analyse. Last Updated: 2018-04-22 \u21a9","title":"Streaming analytics on logs"},{"location":"devposts/multi_processing_queue/","text":"Queue and Multi Processing Pool - Python \u00b6 May 2019 Interfacing multiprocessing queue to delegate tasks to multiprocessing pool in python Code snippet #!/usr/bin/env python3.7 from multiprocessing import Pool , Queue from os import getpid from time import sleep from queue import Empty from random import randint QUEUE_TIMEOUT = 5 # seconds proc_queue = Queue () def worker_fn ( queue : Queue ): print ( f \"{getpid()} working\" ) try : while True : item = queue . get ( block = True , timeout = QUEUE_TIMEOUT ) sleep ( randint ( 1 , 4 )) print ( f \"{getpid()} got {item}\" ) except Empty : print ( f \"{getpid()} stopping\" ) proc_pool = Pool ( processes = 4 , initializer = worker_fn , initargs = ( proc_queue ,)) for i in range ( 10 ): payload = { \"id\" : i } proc_queue . put ( payload ) proc_pool . close () proc_pool . join () Using multiprocessing pool with async worker function and callback Code snippet #!/usr/bin/env python3.7 from os import getpid import multiprocessing from time import sleep def worker_fn ( payload ): sleep ( 1 ) print ( f \"{getpid()} processing {payload}\" ) return f \"{getpid()}-{payload['id']}\" def callback_fn ( val ): print ( f \"callback {val}\" ) if __name__ == \"__main__\" : proc_pool = multiprocessing . Pool ( 4 ) for i in range ( 0 , 10 ): payload = { \"id\" : i } proc_pool . apply_async ( worker_fn , args = ( payload ,), callback = callback_fn ) proc_pool . close () proc_pool . join ()","title":"Multi Processing with Queue"},{"location":"devposts/multi_processing_queue/#queue-and-multi-processing-pool-python","text":"May 2019 Interfacing multiprocessing queue to delegate tasks to multiprocessing pool in python Code snippet #!/usr/bin/env python3.7 from multiprocessing import Pool , Queue from os import getpid from time import sleep from queue import Empty from random import randint QUEUE_TIMEOUT = 5 # seconds proc_queue = Queue () def worker_fn ( queue : Queue ): print ( f \"{getpid()} working\" ) try : while True : item = queue . get ( block = True , timeout = QUEUE_TIMEOUT ) sleep ( randint ( 1 , 4 )) print ( f \"{getpid()} got {item}\" ) except Empty : print ( f \"{getpid()} stopping\" ) proc_pool = Pool ( processes = 4 , initializer = worker_fn , initargs = ( proc_queue ,)) for i in range ( 10 ): payload = { \"id\" : i } proc_queue . put ( payload ) proc_pool . close () proc_pool . join () Using multiprocessing pool with async worker function and callback Code snippet #!/usr/bin/env python3.7 from os import getpid import multiprocessing from time import sleep def worker_fn ( payload ): sleep ( 1 ) print ( f \"{getpid()} processing {payload}\" ) return f \"{getpid()}-{payload['id']}\" def callback_fn ( val ): print ( f \"callback {val}\" ) if __name__ == \"__main__\" : proc_pool = multiprocessing . Pool ( 4 ) for i in range ( 0 , 10 ): payload = { \"id\" : i } proc_pool . apply_async ( worker_fn , args = ( payload ,), callback = callback_fn ) proc_pool . close () proc_pool . join ()","title":"Queue and Multi Processing Pool - Python"},{"location":"devposts/multi_threading_python/","text":"Multi-Threading in Python \u00b6 May 2018 A reference implementation of multi threading network requests for better perfromance with python3. TODO : Parallelize GET requests to fetch data over the network. Creating a Thread Worker class that extends Thread and has a task_queue Set an action_type to reuse the worker for different type of actions that the worker queue can be reused for. from threading import Thread from util.data_util import getData class ThreadWorker(Thread): def __init__(self, queue): Thread.__init__(self) self.task_queue = queue def run(self): while True: action_type, args = self.task_queue.get() if action_type == 'getData': getData(args=args) self.task_queue.task_done() Writing the Data Util for GET requests to fetch data Using **kwargs for generic named param args as a dict. Using an output container to return content. import urllib.request from urllib.error import HTTPError def getData(**kwargs): args = kwargs['args'] try: content = urllib.request.urlopen(args['get_url']).read() except HTTPError: content = None args['output']['content'] = content Creating and starting a multi threaded task queue from queue import Queue task_queue = Queue() for i in range(CPU_COUNT): worker = ThreadWorker(task_queue) worker.daemon = True worker.start() Putting tasks in task queue output1 = {} task_queue.put(('getData',{'get_url' : 'http://google.com','output' : output1})) output2 = {} task_queue.put(('getData',{'get_url' : 'http://example.com','output' : output2})) Waiting for tasks to finish task_queue.join() Output getData for=\"http://example.com\" takes time=0.04711198806762695s getData for=\"http://example.com\" takes time=0.04711198806762695s getData for=\"http://example.com\" takes time=0.04514908790588379s getData for=\"http://google.com\" takes time=0.1752634048461914s getData for=\"http://google.com\" takes time=0.17326903343200684s getData for=\"http://google.com\" takes time=0.1590442657470703s main takes time=0.2101454734802246s serial exec time would be time=0.6469497680664062s Source code: PyUtils/MultiThread","title":"Multi Threading Python"},{"location":"devposts/multi_threading_python/#multi-threading-in-python","text":"May 2018 A reference implementation of multi threading network requests for better perfromance with python3. TODO : Parallelize GET requests to fetch data over the network. Creating a Thread Worker class that extends Thread and has a task_queue Set an action_type to reuse the worker for different type of actions that the worker queue can be reused for. from threading import Thread from util.data_util import getData class ThreadWorker(Thread): def __init__(self, queue): Thread.__init__(self) self.task_queue = queue def run(self): while True: action_type, args = self.task_queue.get() if action_type == 'getData': getData(args=args) self.task_queue.task_done() Writing the Data Util for GET requests to fetch data Using **kwargs for generic named param args as a dict. Using an output container to return content. import urllib.request from urllib.error import HTTPError def getData(**kwargs): args = kwargs['args'] try: content = urllib.request.urlopen(args['get_url']).read() except HTTPError: content = None args['output']['content'] = content Creating and starting a multi threaded task queue from queue import Queue task_queue = Queue() for i in range(CPU_COUNT): worker = ThreadWorker(task_queue) worker.daemon = True worker.start() Putting tasks in task queue output1 = {} task_queue.put(('getData',{'get_url' : 'http://google.com','output' : output1})) output2 = {} task_queue.put(('getData',{'get_url' : 'http://example.com','output' : output2})) Waiting for tasks to finish task_queue.join() Output getData for=\"http://example.com\" takes time=0.04711198806762695s getData for=\"http://example.com\" takes time=0.04711198806762695s getData for=\"http://example.com\" takes time=0.04514908790588379s getData for=\"http://google.com\" takes time=0.1752634048461914s getData for=\"http://google.com\" takes time=0.17326903343200684s getData for=\"http://google.com\" takes time=0.1590442657470703s main takes time=0.2101454734802246s serial exec time would be time=0.6469497680664062s Source code: PyUtils/MultiThread","title":"Multi-Threading in Python"},{"location":"devposts/multiple_git/","text":"Set up multiple git user accounts on your machine per repository \u00b6 Nov 2018 Multiple SSH Keys for different github accounts generate and add ssh keys for both users user1 and user2 \u00b6 user1 ssh-keygen -t rsa -b 4096 -C \"<user1@email.com>\" /home/user/.ssh/id_user1 user2 ssh-keygen -t rsa -b 4096 -C \"<user2@email.com>\" /home/user/.ssh/id_user2 sshconfig ~/.ssh/config \u00b6 # default account identity - set to user1 Host github.com HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user1 Host github.com-user1 HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user2 Host github.com-user2 HostName github.com User git IdentityFile /home/user/.ssh/id_user2 reset all global git settings \u00b6 git config --global user.useConfigOnly true git config --global --unset-all user.name git config --global --unset-all user.email set the repo \u00b6 clone a repo set repo level .git/.gitconfig, eg: git config user.name \"user1\" git config user.email \"user1l@email.com\" to explicitly use a user specific setting update the remote to git clone git@github.com-user1:user1/repo.git Last Updated: 2018-11-02 \u21a9","title":"Multiple Git Accounts"},{"location":"devposts/multiple_git/#set-up-multiple-git-user-accounts-on-your-machine-per-repository","text":"Nov 2018 Multiple SSH Keys for different github accounts","title":"Set up multiple git user accounts on your machine per repository"},{"location":"devposts/multiple_git/#generate-and-add-ssh-keys-for-both-users-user1-and-user2","text":"user1 ssh-keygen -t rsa -b 4096 -C \"<user1@email.com>\" /home/user/.ssh/id_user1 user2 ssh-keygen -t rsa -b 4096 -C \"<user2@email.com>\" /home/user/.ssh/id_user2","title":"generate and add ssh keys for both users user1 and user2"},{"location":"devposts/multiple_git/#sshconfig-sshconfig","text":"# default account identity - set to user1 Host github.com HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user1 Host github.com-user1 HostName github.com User git IdentityFile /home/user/.ssh/id_user1 # explicit account identity - user2 Host github.com-user2 HostName github.com User git IdentityFile /home/user/.ssh/id_user2","title":"sshconfig ~/.ssh/config"},{"location":"devposts/multiple_git/#reset-all-global-git-settings","text":"git config --global user.useConfigOnly true git config --global --unset-all user.name git config --global --unset-all user.email","title":"reset all global git settings"},{"location":"devposts/multiple_git/#set-the-repo","text":"clone a repo set repo level .git/.gitconfig, eg: git config user.name \"user1\" git config user.email \"user1l@email.com\" to explicitly use a user specific setting update the remote to git clone git@github.com-user1:user1/repo.git Last Updated: 2018-11-02 \u21a9","title":"set the repo"},{"location":"devposts/root-rom-samsung/","text":"Root and Custom ROM Samsung Android Phone \u00b6 Nov 2018 After recently having bricked my realtively new One Plus 5 phone on a recent motorbiking trip (albeit biking on the highest motorable road in the world), I decided to overhaul my 2014 Samsung Galaxy Grand 2. Here is a summary of my experience overhauling it to get it to work rather smoothly. Flash TWRP recovery using Odin \u00b6 TWRP 3.0.0 Recovery Samsung Win Drivers Odin 3.07 Install Cyanogenmod ROM+ \u00b6 Boot in TWRP recovery Cyanogenmod 13 Patch 1 Patch 2 Bare minimum GApps, ARM-6.0-pico Install Cyanogenmod ROM + Patches + GApps Root the phone \u00b6 Boot into TWRP recovery SuperSU flashable Install SuperSU Rerference Links \u00b6 https://forum.xda-developers.com/galaxy-grand-2/orig-development/rom-cyanogenmod-13-galaxy-grand-2-t3485393 https://www.cyanogenmods.org/forums/topic/galaxy-grand-2-cm13-cyanogenmod-13-marshmallow-rom-sm-g7102/","title":"Root & Custom Rom Android"},{"location":"devposts/root-rom-samsung/#root-and-custom-rom-samsung-android-phone","text":"Nov 2018 After recently having bricked my realtively new One Plus 5 phone on a recent motorbiking trip (albeit biking on the highest motorable road in the world), I decided to overhaul my 2014 Samsung Galaxy Grand 2. Here is a summary of my experience overhauling it to get it to work rather smoothly.","title":"Root and Custom ROM Samsung Android Phone"},{"location":"devposts/root-rom-samsung/#flash-twrp-recovery-using-odin","text":"TWRP 3.0.0 Recovery Samsung Win Drivers Odin 3.07","title":"Flash TWRP recovery using Odin"},{"location":"devposts/root-rom-samsung/#install-cyanogenmod-rom","text":"Boot in TWRP recovery Cyanogenmod 13 Patch 1 Patch 2 Bare minimum GApps, ARM-6.0-pico Install Cyanogenmod ROM + Patches + GApps","title":"Install Cyanogenmod ROM+"},{"location":"devposts/root-rom-samsung/#root-the-phone","text":"Boot into TWRP recovery SuperSU flashable Install SuperSU","title":"Root the phone"},{"location":"devposts/root-rom-samsung/#rerference-links","text":"https://forum.xda-developers.com/galaxy-grand-2/orig-development/rom-cyanogenmod-13-galaxy-grand-2-t3485393 https://www.cyanogenmods.org/forums/topic/galaxy-grand-2-cm13-cyanogenmod-13-marshmallow-rom-sm-g7102/","title":"Rerference Links"},{"location":"devposts/sde-journaling-guide/","text":"A Software Engineer's Guide to Journaling \u00b6 Apr 2019 A Software Engineer's Guide to Journaling To impart value you need to make sense and to make sense you need to be able to see how an idea evolves, thus Journaling.Personally having experimented with various tools and strategies that go along with each one of them I was finally able to settle upon the following as a well defined structured approach with a timeline for each step.","title":"SDE Guide to Journaling"},{"location":"devposts/sde-journaling-guide/#a-software-engineers-guide-to-journaling","text":"Apr 2019","title":"A Software Engineer's Guide to Journaling"},{"location":"drafts/ordinary-emotion/","text":"Ordinary Emotion \u00b6 Aayush Uppal | 2018-04-23 But what is ordinary may never last, yet more often than not it does. Often chasing the grandest of ideas I don't know what it is. So at this point I am not quite sure if there is an ordinary emotion anymore. But what I do know is my perspective has evolved and I feel like I am going to hold dear to the moment.","title":"Ordinary Emotion"},{"location":"drafts/ordinary-emotion/#ordinary-emotion","text":"Aayush Uppal | 2018-04-23 But what is ordinary may never last, yet more often than not it does. Often chasing the grandest of ideas I don't know what it is. So at this point I am not quite sure if there is an ordinary emotion anymore. But what I do know is my perspective has evolved and I feel like I am going to hold dear to the moment.","title":"Ordinary Emotion"}]}